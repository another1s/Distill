# Model Distillation
An easy deployed 

1. Base model 
    * Roberta
    * Electra
    * Bert
2. Distillation strategy
    * teacher model output + intermediate layer + student output loss
